{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eb8a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds  # TFDS to download MNIST.\n",
    "import tensorflow as tf  # TensorFlow / `tf.data` operations.\n",
    "\n",
    "tf.random.set_seed(0)  # Set the random seed for reproducibility.\n",
    "\n",
    "train_steps = 1200\n",
    "eval_every = 200\n",
    "batch_size = 32\n",
    "\n",
    "train_ds: tf.data.Dataset = tfds.load('mnist', split='train')\n",
    "test_ds: tf.data.Dataset = tfds.load('mnist', split='test')\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "  lambda sample: {\n",
    "    'image': tf.cast(sample['image'], tf.float32) / 255,\n",
    "    'label': sample['label'],\n",
    "  }\n",
    ")  # normalize train set\n",
    "test_ds = test_ds.map(\n",
    "  lambda sample: {\n",
    "    'image': tf.cast(sample['image'], tf.float32) / 255,\n",
    "    'label': sample['label'],\n",
    "  }\n",
    ")  # Normalize the test set.\n",
    "\n",
    "# Create a shuffled dataset by allocating a buffer size of 1024 to randomly draw elements from.\n",
    "train_ds = train_ds.repeat().shuffle(1024)\n",
    "# Group into batches of `batch_size` and skip incomplete batches, prefetch the next sample to improve latency.\n",
    "train_ds = train_ds.batch(batch_size, drop_remainder=True).take(train_steps).prefetch(1)\n",
    "# Group into batches of `batch_size` and skip incomplete batches, prefetch the next sample to improve latency.\n",
    "test_ds = test_ds.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4cde9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import nnx  # The Flax NNX API.\n",
    "from functools import partial\n",
    "\n",
    "class CNN(nnx.Module):\n",
    "  \"\"\"A simple CNN model.\"\"\"\n",
    "\n",
    "  def __init__(self, *, rngs: nnx.Rngs):\n",
    "    self.conv1 = nnx.Conv(1, 32, kernel_size=(3, 3), rngs=rngs)\n",
    "    self.batch_norm1 = nnx.BatchNorm(32, rngs=rngs)\n",
    "    self.dropout1 = nnx.Dropout(rate=0.025, rngs=rngs)\n",
    "    self.conv2 = nnx.Conv(32, 64, kernel_size=(3, 3), rngs=rngs)\n",
    "    self.batch_norm2 = nnx.BatchNorm(64, rngs=rngs)\n",
    "    self.avg_pool = partial(nnx.avg_pool, window_shape=(2, 2), strides=(2, 2))\n",
    "    self.linear1 = nnx.Linear(3136, 256, rngs=rngs)\n",
    "    self.dropout2 = nnx.Dropout(rate=0.025, rngs=rngs)\n",
    "    self.linear2 = nnx.Linear(256, 10, rngs=rngs)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    x = self.avg_pool(nnx.relu(self.batch_norm1(self.dropout1(self.conv1(x)))))\n",
    "    x = self.avg_pool(nnx.relu(self.batch_norm2(self.conv2(x))))\n",
    "    x = x.reshape(x.shape[0], -1)  # flatten\n",
    "    x = nnx.relu(self.dropout2(self.linear1(x)))\n",
    "    x = self.linear2(x)\n",
    "    return x\n",
    "\n",
    "# Instantiate the model.\n",
    "model = CNN(rngs=nnx.Rngs(0))\n",
    "# Visualize it.\n",
    "nnx.display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e031bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp  # JAX NumPy\n",
    "\n",
    "y = model(jnp.ones((1, 28, 28, 1)))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1703f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "learning_rate = 0.005\n",
    "momentum = 0.9\n",
    "\n",
    "optimizer = nnx.Optimizer(\n",
    "  model, optax.adamw(learning_rate, momentum), wrt=nnx.Param\n",
    ")\n",
    "metrics = nnx.MultiMetric(\n",
    "  accuracy=nnx.metrics.Accuracy(),\n",
    "  loss=nnx.metrics.Average('loss'),\n",
    ")\n",
    "\n",
    "nnx.display(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1220155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model: CNN, batch):\n",
    "  logits = model(batch['image'])\n",
    "  loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "    logits=logits, labels=batch['label']\n",
    "  ).mean()\n",
    "  return loss, logits\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model: CNN, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, batch):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "  grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
    "  (loss, logits), grads = grad_fn(model, batch)\n",
    "  metrics.update(loss=loss, logits=logits, labels=batch['label'])  # In-place updates.\n",
    "  optimizer.update(grads)  # In-place updates.\n",
    "\n",
    "@nnx.jit\n",
    "def eval_step(model: CNN, metrics: nnx.MultiMetric, batch):\n",
    "  loss, logits = loss_fn(model, batch)\n",
    "  metrics.update(loss=loss, logits=logits, labels=batch['label'])  # In-place updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c242c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics_history = {\n",
    "  'train_loss': [],\n",
    "  'train_accuracy': [],\n",
    "  'test_loss': [],\n",
    "  'test_accuracy': [],\n",
    "}\n",
    "\n",
    "for step, batch in enumerate(train_ds.as_numpy_iterator()):\n",
    "  # Run the optimization for one step and make a stateful update to the following:\n",
    "  # - The train state's model parameters\n",
    "  # - The optimizer state\n",
    "  # - The training loss and accuracy batch metrics\n",
    "  model.train() # Switch to train mode\n",
    "  train_step(model, optimizer, metrics, batch)\n",
    "\n",
    "  if step > 0 and (step % eval_every == 0 or step == train_steps - 1):  # One training epoch has passed.\n",
    "    # Log the training metrics.\n",
    "    for metric, value in metrics.compute().items():  # Compute the metrics.\n",
    "      metrics_history[f'train_{metric}'].append(value)  # Record the metrics.\n",
    "    metrics.reset()  # Reset the metrics for the test set.\n",
    "\n",
    "    # Compute the metrics on the test set after each training epoch.\n",
    "    model.eval() # Switch to eval mode\n",
    "    for test_batch in test_ds.as_numpy_iterator():\n",
    "      eval_step(model, metrics, test_batch)\n",
    "\n",
    "    # Log the test metrics.\n",
    "    for metric, value in metrics.compute().items():\n",
    "      metrics_history[f'test_{metric}'].append(value)\n",
    "    metrics.reset()  # Reset the metrics for the next training epoch.\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    # Plot loss and accuracy in subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.set_title('Loss')\n",
    "    ax2.set_title('Accuracy')\n",
    "    for dataset in ('train', 'test'):\n",
    "      ax1.plot(metrics_history[f'{dataset}_loss'], label=f'{dataset}_loss')\n",
    "      ax2.plot(metrics_history[f'{dataset}_accuracy'], label=f'{dataset}_accuracy')\n",
    "    ax1.legend()\n",
    "    ax2.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd312c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # Switch to evaluation mode.\n",
    "\n",
    "@nnx.jit\n",
    "def pred_step(model: CNN, batch):\n",
    "  logits = model(batch['image'])\n",
    "  return logits.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24023074",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = test_ds.as_numpy_iterator().next()\n",
    "pred = pred_step(model, test_batch)\n",
    "\n",
    "fig, axs = plt.subplots(5, 5, figsize=(12, 12))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "  ax.imshow(test_batch['image'][i, ..., 0], cmap='gray')\n",
    "  ax.set_title(f'label={pred[i]}')\n",
    "  ax.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_rom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
